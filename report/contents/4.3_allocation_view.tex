% 3.3 Allocation View

% Trong kiáº¿n trÃºc On-Premise, há»‡ thá»‘ng ITS Ä‘Æ°á»£c triá»ƒn khai hoÃ n toÃ n trÃªn háº¡ táº§ng ná»™i bá»™ (private infrastructure), bao gá»“m:
% 	â€¢	CÃ¡c Server váº­t lÃ½ hoáº·c Virtual Machines trong trung tÃ¢m dá»¯ liá»‡u.
% 	â€¢	Má»™t Kubernetes Cluster tá»± quáº£n lÃ½ (Self-managed K8s) do Ä‘á»™i IT váº­n hÃ nh.
% 	â€¢	CÃ¡c thÃ nh pháº§n lÆ°u trá»¯, máº¡ng vÃ  giÃ¡m sÃ¡t Ä‘Æ°á»£c triá»ƒn khai cá»¥c bá»™.

% GÃ³c nhÃ¬n nÃ y Ã¡nh xáº¡ cÃ¡c thÃ nh pháº§n kiáº¿n trÃºc (Service Components) tá»« Má»¥c 3.2 vÃ o cÃ¡c tÃ i nguyÃªn váº­t lÃ½ vÃ  áº£o táº¡i trung tÃ¢m dá»¯ liá»‡u On-Premise.

% ğŸ”— LiÃªn káº¿t vá»›i pháº§n trÆ°á»›c:
% 	â€¢	3.1 Module View â†’ cho biáº¿t cáº¥u trÃºc code.
% 	â€¢	3.2 Component & Connector View â†’ cho biáº¿t cÃ¡c thÃ nh pháº§n vÃ  cÃ¡ch chÃºng giao tiáº¿p.
% 	â€¢	3.3 Allocation View â†’ mÃ´ táº£ chÃºng cháº¡y trÃªn mÃ¡y chá»§/vÃ¹ng máº¡ng nÃ o, vá»›i cÆ¡ cháº¿ HA vÃ  DR ra sao trong mÃ´i trÆ°á»ng On-Premise.

% Má»¥c tiÃªu cá»§a Deployment View trong On-Premise:
% 	â€¢	AC2 â€“ Scalability: Scale-out báº±ng Node Pools vÃ  tá»± Ä‘á»™ng phÃ¢n phá»‘i workload.
% 	â€¢	AC5 â€“ Deployability: Tá»± Ä‘á»™ng hÃ³a CI/CD ná»™i bá»™, sá»­ dá»¥ng Container Registry riÃªng.
% 	â€¢	AC9 â€“ Observability: Quáº£n lÃ½ logs/metrics phÃ¢n tÃ¡n trong háº¡ táº§ng ná»™i bá»™.
% 	â€¢	High Availability & Fault Tolerance: Äáº£m báº£o há»‡ thá»‘ng cháº¡y á»•n Ä‘á»‹nh ngay cáº£ khi má»™t node hoáº·c tá»§ rack gáº·p sá»± cá»‘.

% â¸»

% 3.3.1 Deployment Architecture (On-Premise Architecture)

% Kiáº¿n trÃºc triá»ƒn khai On-Premise váº«n tuÃ¢n thá»§ nguyÃªn táº¯c Cloud-Native, nhÆ°ng táº¥t cáº£ thÃ nh pháº§n Ä‘Æ°á»£c host trÃªn:
% 	â€¢	MÃ¡y chá»§ váº­t lÃ½ (Bare-metal servers) vá»›i CPU/RAM cao.
% 	â€¢	Há»‡ thá»‘ng lÆ°u trá»¯ SAN/NAS cho database vÃ  persistent volumes.
% 	â€¢	Há»‡ thá»‘ng áº£o hÃ³a ná»™i bá»™ (VMware vSphere / Proxmox / OpenStack) cho Kubernetes nodes.
% 	â€¢	Load Balancer cá»©ng (hardware LB) hoáº·c HAProxy/NGINX ná»™i bá»™.
% 	â€¢	Private Docker Registry Ä‘á»ƒ lÆ°u images.

% ğŸ–¥ï¸ Háº¡ táº§ng pháº§n cá»©ng (Physical Infrastructure Layer)

% ThÃ nh pháº§n	MÃ´ táº£
% Rack Servers	6â€“10 server váº­t lÃ½, CPU Intel Xeon/AMD EPYC, RAM 128â€“256GB
% Network	Switch Layer 2/3, VLAN tÃ¡ch biá»‡t (DMZ / Internal / Storage)
% Storage	SAN/NAS há»— trá»£ RAID-10, Fiber Channel/iSCSI
% Management	vCenter/Proxmox Dashboard cho quáº£n lÃ½ VM


% â¸»

% ğŸ§© Kubernetes Cluster (Self-Managed)

% Há»‡ thá»‘ng cháº¡y trÃªn má»™t cluster Kubernetes tá»± triá»ƒn khai:

% ThÃ nh pháº§n	MÃ´ táº£
% Master Nodes	3 master Ä‘á»ƒ Ä‘áº£m báº£o HA (etcd cluster)
% Worker Nodes	6â€“12 worker (tuá»³ táº£i)
% CNI	Calico hoáº·c Cilium
% Ingress	NGINX Ingress hoáº·c Istio Gateway
% Persistent Volumes	Rook-Ceph / Longhorn / NFS


% â¸»

% ğŸŒ Network Segmentation

% VÃ¬ Ä‘Ã¢y lÃ  mÃ´i trÆ°á»ng On-Premise, viá»‡c phÃ¢n vÃ¹ng máº¡ng (segmentation) lÃ  cá»±c ká»³ quan trá»ng:
% 	â€¢	DMZ Layer â†’ Load Balancer + API Gateway.
% 	â€¢	Application Layer â†’ cÃ¡c pod Java/Go.
% 	â€¢	Data Layer â†’ PostgreSQL, MongoDB, RabbitMQ, Redis.
% 	â€¢	Monitoring Layer â†’ Prometheus, Grafana, Loki.

% â¸»

% ğŸ–¼ï¸ HÃŒNH 3.10 â€“ Deployment Architecture (On-Premise)

% Gá»£i Ã½ khi váº½ báº£n Ä‘áº¹p (Figma / Draw.io):
% 	â€¢	TÃ¡ch thÃ nh 3 táº§ng: DMZ â†’ App Nodes â†’ Data Nodes.
% 	â€¢	DÃ¹ng icon server Ä‘á»ƒ thá»ƒ hiá»‡n Bare-metal.
% 	â€¢	DÃ¹ng mÃ u pastel Ä‘á»ƒ Ä‘áº£m báº£o tÃ­nh academic.

% DÆ°á»›i Ä‘Ã¢y lÃ  báº£n Mermaid Ä‘á»ƒ báº¡n xem logic:

% graph TD
%     subgraph Users
%         User(User<br/>Learner / Instructor / Admin)
%     end

%     subgraph DMZ["DMZ Network (On-Prem Load Balancer)"]
%         LB(Hardware Load Balancer<br/>HAProxy/NGINX)
%     end

%     subgraph OnPremCluster["On-Premise Kubernetes Cluster"]
%         direction TB

%         Ingress(Ingress Controller<br/>TLS Termination)

%         subgraph "Namespace: its-prod"
%             APIPod(API Gateway Pods<br/>Go)
%             JavaPods(Java Services<br/>Auth / User / Content)
%             GoPods(Go Services<br/>Scoring / Adaptive / Learner Model)
%         end

%         subgraph "Namespace: its-monitoring"
%             Mon(Prometheus â€¢ Loki â€¢ Grafana)
%         end
%     end

%     subgraph DataZone["Data Zone (Bare-metal / VMs)"]
%         PG[(ğŸ˜ PostgreSQL<br/>Primary + Standby)]
%         MG[(ğŸƒ MongoDB<br/>Replica Set)]
%         RD[(ğŸ”¥ Redis HA Cluster)]
%         MQ[(ğŸ° RabbitMQ<br/>Clustered)]
%     end

%     User --> LB --> Ingress
%     Ingress --> APIPod
%     Ingress --> JavaPods
%     Ingress --> GoPods

%     JavaPods -- JDBC --> PG
%     JavaPods -- Redis --> RD

%     GoPods -- Mongo --> MG
%     GoPods -- JDBC --> PG
%     GoPods -- AMQP --> MQ

%     APIPod -- AMQP --> MQ
%     Mon --- APIPod
%     Mon --- JavaPods
%     Mon --- GoPods


% â¸»

% 3.3.2 Container Specifications (On-Premise Resource Planning)

% Do há»‡ thá»‘ng cháº¡y On-Premise, tÃ i nguyÃªn cáº§n Ä‘Æ°á»£c quy hoáº¡ch tÄ©nh (static capacity planning), káº¿t há»£p vá»›i autoscaling dá»±a trÃªn metrics nhÆ°ng bá»‹ rÃ ng buá»™c bá»Ÿi tÃ i nguyÃªn pháº§n cá»©ng.

% Service	Image Size	Memory Req/Lmt	CPU Req/Lmt	Replicas	Node Pool
% API Gateway (Go)	30MB	256MB/512MB	0.25/1	3â€“10	Node Pool A
% Auth Service (Java)	250MB	512MB/1GB	0.5/1.5	2â€“5	Node Pool B
% User Service (Java)	250MB	512MB/1GB	0.5/1.5	2â€“5	Node Pool B
% Content Service (Java)	250MB	512MB/1GB	0.5/1.5	2â€“5	Node Pool B
% Scoring Svc (Go)	40MB	256MB/1GB	0.5/2	3â€“15	Node Pool A
% Learner Model (Go)	40MB	256MB/1GB	0.5/2	3â€“10	Node Pool A
% Adaptive Engine (Go)	40MB	512MB/2GB	1/3	2â€“8	Node Pool A


% â¸»

% 3.3.3 Infrastructure Components (On-Premise Stack)

% DÆ°á»›i Ä‘Ã¢y lÃ  toÃ n bá»™ thÃ nh pháº§n háº¡ táº§ng báº¯t buá»™c khi triá»ƒn khai ITS On-Premise.

% â¸»

% 1ï¸âƒ£ Load Balancer (Lá»›p DMZ)
% 	â€¢	CÃ³ thá»ƒ dÃ¹ng:
% 	â€¢	HAProxy (active-passive)
% 	â€¢	NGINX Plus
% 	â€¢	F5 BIG-IP (náº¿u doanh nghiá»‡p cÃ³ sáºµn)
% 	â€¢	Chá»©c nÄƒng:
% 	â€¢	SSL termination
% 	â€¢	Reverse proxy
% 	â€¢	Rate limit
% 	â€¢	WAF

% â¸»

% 2ï¸âƒ£ Database & Storage Zone

% ğŸ˜ PostgreSQL HA Cluster
% 	â€¢	Patroni + etcd hoáº·c
% 	â€¢	pgPool-II + Streaming Replication

% ğŸƒ MongoDB Replica Set
% 	â€¢	Cháº¡y 3 node trong cÃ¡c rack khÃ¡c nhau.

% ğŸ”¥ Redis Sentinel Cluster
% 	â€¢	DÃ¹ng local SSD cá»§a server Ä‘á»ƒ Ä‘áº¡t IOPS cao.

% ğŸ° RabbitMQ Cluster
% 	â€¢	Mirrored queues (Highly Available).
% 	â€¢	PhÃ¹ há»£p vá»›i Adaptive Learning & Scoring Event-driven flow.

% â¸»

% 3ï¸âƒ£ Observability Stack (AC9 â€“ On-Premise)

% ToÃ n bá»™ stack giÃ¡m sÃ¡t Ä‘Æ°á»£c cÃ i trong namespace its-monitoring.
% 	â€¢	Prometheus â€“ metrics (scrape tá»« pods + node exporter)
% 	â€¢	Loki â€“ collector logs
% 	â€¢	Grafana â€“ dashboard há»£p nháº¥t
% 	â€¢	Alertmanager â€“ cáº£nh bÃ¡o ná»™i bá»™ (email/SMS/Zalo OA)
% 	â€¢	OpenTelemetry Collector â€“ gá»­i trace tá»« Java/Go Ä‘áº¿n Tempo/Jaeger
% 	â€¢	Node Exporter â€“ metrics pháº§n cá»©ng cá»§a má»—i server

% â¸»

% TÃ“M Táº®T (TL;DR)

% Cloud	On-Premise
% Autoscaling theo tÃ i nguyÃªn khÃ´ng giá»›i háº¡n	Scale bá»‹ giá»›i háº¡n bá»Ÿi sá»‘ server váº­t lÃ½
% Managed Databases	Tá»± quáº£n lÃ½ DB HA (Patroni/Mongo Replica Set)
% Load Balancer do Cloud cung cáº¥p	HAProxy/NGINX hoáº·c thiáº¿t bá»‹ pháº§n cá»©ng
% Observability Cloud Services	Tá»± triá»ƒn khai Prometheus + Loki + Grafana
% Storage quáº£n lÃ½ bá»Ÿi cloud	SAN/NAS + CSI Driver


% â¸»

% Náº¿u báº¡n muá»‘n, mÃ¬nh cÃ³ thá»ƒ viáº¿t thÃªm 3.3.4 CI/CD Pipeline (On-Premise) hoáº·c 3.4 Runtime View, hoáº·c váº½ láº¡i HÃ¬nh 3.10 theo style Draw.io Ä‘áº¹p chuáº©n doanh nghiá»‡p.

% Báº¡n muá»‘n tiáº¿p tá»¥c pháº§n nÃ o?